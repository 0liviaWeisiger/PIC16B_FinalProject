{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174e390b",
   "metadata": {},
   "source": [
    "# Predicting United States Real Estate Prices\n",
    "By: Grace Li, Olivia Weisiger and Fionnuala Eastwood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054bf35",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Dataset Preprocessing and Merging\n",
    "2. Data Visualization\n",
    "3. Classic Machine Learning Models\n",
    "4. Deep Learning Models\n",
    "5. Analysis of accuracy and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6a3cb",
   "metadata": {},
   "source": [
    "### Context\n",
    "The United States housing market is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ff604",
   "metadata": {},
   "source": [
    "### Our Goal\n",
    "\n",
    "This project will explore the current United States real-estate market, investigate what factors influence the price of property, and create multiple machine learning models that predict these housing costs throughout the country. More specifically, this will be accomplished through implementation of (add briefly about what models we end up using....) Being able to infer and understand the trends of real estate is extremely valuable economic knowledge that will provide important insights about our country. \n",
    "\n",
    "Furthermore, our project aims to deepen our understanding of how societal biases influence external structures such as the economy. By merging datasets, we will investigate which underlying factors such as (add briefly when choose other data) affect the prices of houses in order to draw deeper conclusions about intangible factors impacting our economic climate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5441e62",
   "metadata": {},
   "source": [
    "### Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d47e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b767510",
   "metadata": {},
   "source": [
    "This data is from Kaggle's \"USA Real Estate Dataset\" found here: https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c01278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('realtor-data.zip.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba8cab",
   "metadata": {},
   "source": [
    "### Initial Data Processing\n",
    "Let's first break down what our dataset looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3990b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2226382, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881d372",
   "metadata": {},
   "source": [
    "We have a dataset with over 2 million rows and 12 columns. Since this is way too many samples to process in a reasonable computational time, we will take a random subset of 100,000 of these samples to perform analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac630652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 12)\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "df = df.sample(50000)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95024cfe",
   "metadata": {},
   "source": [
    "With our refined sample, let's get an idea of what our dataset looks like by outputting a few rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111beab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1829353</th>\n",
       "      <td>31344.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>2022-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643751</th>\n",
       "      <td>6916.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>1295000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>246711.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>30306.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566334</th>\n",
       "      <td>25789.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>731970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>470944.0</td>\n",
       "      <td>Bradenton</td>\n",
       "      <td>Florida</td>\n",
       "      <td>34211.0</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616655</th>\n",
       "      <td>92089.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.40</td>\n",
       "      <td>1880375.0</td>\n",
       "      <td>Gainesboro</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>38562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754326</th>\n",
       "      <td>30253.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1624264.0</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>49202.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>2013-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brokered_by    status      price  bed  bath  acre_lot     street  \\\n",
       "1829353      31344.0      sold   300000.0  3.0   2.0      0.32  1728557.0   \n",
       "1643751       6916.0      sold  1295000.0  4.0   4.0      0.20   246711.0   \n",
       "566334       25789.0  for_sale   731970.0  4.0   3.0      0.19   470944.0   \n",
       "616655       92089.0  for_sale    94000.0  NaN   NaN     10.40  1880375.0   \n",
       "754326       30253.0  for_sale   140000.0  2.0   1.0      0.14  1624264.0   \n",
       "\n",
       "               city      state  zip_code  house_size prev_sold_date  \n",
       "1829353    New Hope  Minnesota   55427.0      2990.0     2022-03-08  \n",
       "1643751     Atlanta    Georgia   30306.0      2543.0     2022-04-04  \n",
       "566334    Bradenton    Florida   34211.0      2537.0            NaN  \n",
       "616655   Gainesboro  Tennessee   38562.0         NaN            NaN  \n",
       "754326      Jackson   Michigan   49202.0       931.0     2013-12-17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c8b99",
   "metadata": {},
   "source": [
    "Notice that each sample in the dataset is a real estate listing in the United States (the listings are all from 2022-2024), and each sample has 12 features that provide numerical or categorical information about the listing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dd10b",
   "metadata": {},
   "source": [
    "Here is an overview of each feature's meaning and data type:\n",
    "\n",
    "- brokered_by:\n",
    "\n",
    "- status:\n",
    "\n",
    "- price:\n",
    "\n",
    "- bed:\n",
    "\n",
    "- bath:\n",
    "\n",
    "- etc fill in later (look on kaggle these descriptins are provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9f616",
   "metadata": {},
   "source": [
    "Now that we have an understanding of our data set, we will perform some processing on the data so that it is cleaner to use. Firstly, we will drop some unnecessary columns that do not contribute to our analysis goals. The brokered_by column which encodes the real-estate company in charge of the property is not necessary because we are interested in the qualities of the house itself. Additionally, the status column is not needed because we will use the price set for the house equivalently regardless if it is sold or for sale. Lastly, the previously sold date can be dropped since we are focused on the current selling price. We will trim our dataset from 12 columns to 9 with these modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f20f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['brokered_by', 'status', 'prev_sold_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86679a9",
   "metadata": {},
   "source": [
    "This dataset contains listings from the United States and all it's territories. For our purposes, we only want to analyze data from the 50 states (and Washington, DC) so let's trim out samples taken from Puerto Rico and the Virgin Islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac992a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['state'] != \"Puerto Rico\") & (df['state'] != \"Virgin Islands\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb20ef2",
   "metadata": {},
   "source": [
    "Our next processing step is making sure we don't have any NaN's in our dataset, as empty data values might impact our analysis models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd41e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42610\n"
     ]
    }
   ],
   "source": [
    "#sum up all NaN values present in dataset (in any feature column)\n",
    "print (df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe21dbe",
   "metadata": {},
   "source": [
    "We see that we have some data entries with no value, so let's remove all rows that contain any NaN values. We will also check the shape of our data frame after this removal to make sure we still have plenty of samples to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed4f3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have: 0 NaN entires\n",
      "Our new dataset shape is (30328, 9)\n"
     ]
    }
   ],
   "source": [
    "#remove all rows missing data\n",
    "df = df.dropna()\n",
    "\n",
    "#verify we now have no NaN values, expect a value of zero\n",
    "print (f'We now have: {df.isnull().sum().sum()} NaN entires')\n",
    "\n",
    "#print new shape\n",
    "print (f'Our new dataset shape is {df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3699592",
   "metadata": {},
   "source": [
    "We successfully dropped all empty entries and still have a substantial size data frame to analyze.\n",
    "\n",
    "Our last step in data processing is preparing our target price data for our future machine learning models. We noticed that predicting the price to an exact number (as the current column does) is quite specific, so instead in some cases we will want to predict whether any piece of real-estate is more generally expensive or cheap. The next question that follows is how we will quantify this \"expensive\" vs \"cheap\". \n",
    "\n",
    "Our natural thought was just categorizing the samples based on if they were on the higher half of all in our dataset vs the lowest. However, upon further analysis we realize that the state the property is in has an overwhelmingly powerful influence on this categorization. For example we would see that practically all samples from New York would fall in the upper portion of data, while a huge majority of samples from rural states will be in the lower. This would leave our model with very little to do, so to work around this we have decided to create a categorical column that contains a 1 if the property price is above the median housing price **of the state it is in**, and a 0 if the property is below this median average of its state. This takes out the state bias and may lead to more informative conclusions about other features that are no longer overshadowed.\n",
    "\n",
    "To do this, we first merge data with the median housing prices by state. This data was taken from the following link: https://www.bankrate.com/real-estate/median-home-price/#how-much, and is up to date as of November 2023 (which is the same time period our real-estate data was taken from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c87444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>med_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>$330,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>$330,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>$330,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1542009.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>$330,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1812742.0</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55447.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>$330,500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street          city      state  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0      New Hope  Minnesota   \n",
       "1  399000.0  4.0   2.0      2.69   559528.0     Oak Grove  Minnesota   \n",
       "2  394900.0  4.0   3.0      0.24   497833.0  New Brighton  Minnesota   \n",
       "3  650000.0  4.0   3.0      0.19  1542009.0  New Brighton  Minnesota   \n",
       "4  419000.0  3.0   2.0      0.08  1812742.0      Plymouth  Minnesota   \n",
       "\n",
       "   zip_code  house_size med_price  \n",
       "0   55427.0      2990.0  $330,500  \n",
       "1   55011.0      2400.0  $330,500  \n",
       "2   55112.0      2107.0  $330,500  \n",
       "3   55112.0      2968.0  $330,500  \n",
       "4   55447.0      1152.0  $330,500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload data\n",
    "df_med = pd.read_csv('median_prices.csv')\n",
    "df_med.head()\n",
    "\n",
    "#select state and median price columns we want\n",
    "df_med = df_med[[\"state\", \"med_price\"]]\n",
    "\n",
    "#merge along state column\n",
    "df = pd.merge(df, df_med, on = [\"state\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43110e9c",
   "metadata": {},
   "source": [
    "Notice one more problem exists: we have a price listed in string form with dollar sign and commas. Instead we want it to be numerical in order to compare it with our current price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5152e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dollar signs and commas, then convert to integers\n",
    "df['med_price'] = df['med_price'].replace({'\\$': '', ',': ''}, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776bdde",
   "metadata": {},
   "source": [
    "Lastly, we want to create a new column which we will call above_average. This column will contain a 1 if the price of that sample is above the median price in the state, and a 0 if it is below. We will also remove the median price column afterwards because it served its purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be76f33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>above_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1542009.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1812742.0</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55447.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street          city      state  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0      New Hope  Minnesota   \n",
       "1  399000.0  4.0   2.0      2.69   559528.0     Oak Grove  Minnesota   \n",
       "2  394900.0  4.0   3.0      0.24   497833.0  New Brighton  Minnesota   \n",
       "3  650000.0  4.0   3.0      0.19  1542009.0  New Brighton  Minnesota   \n",
       "4  419000.0  3.0   2.0      0.08  1812742.0      Plymouth  Minnesota   \n",
       "\n",
       "   zip_code  house_size  above_average  \n",
       "0   55427.0      2990.0              0  \n",
       "1   55011.0      2400.0              1  \n",
       "2   55112.0      2107.0              1  \n",
       "3   55112.0      2968.0              1  \n",
       "4   55447.0      1152.0              1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['above_average'] = df.apply(lambda row: 1 if row['price'] > row['med_price'] else 0, axis=1)\n",
    "df = df.drop('med_price', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b4759d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30327, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429dfae",
   "metadata": {},
   "source": [
    "This looks good, now we are ready to merge with other data sets to add more features to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6f273",
   "metadata": {},
   "source": [
    "### Dataset Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa728de8",
   "metadata": {},
   "source": [
    "While the relationship between features such as number of rooms or number of acres on real-estate prices is quite intuitive, this project aims to delve beyond these variables and investigate more abstract influences. This will be done by merging our current dataframe with new datasets in order to add features including minimum wage of the state, median income by zip code, and even political affiliation, as we are curious if any of these variables will display a strong correlation with housing prices. One caution to note is that our original real estate data is from the past two years, so we will need to make sure the data we are merging with is taken from the same time period in order to obtain accurate conclusions.\n",
    "\n",
    "The first dataset we will merge with is Kaggle's \"US Household Income by Zip Code 2021-2011\" found here: https://www.kaggle.com/datasets/claygendron/us-household-income-by-zip-code-2021-2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3e13c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Geographic Area Name</th>\n",
       "      <th>Households</th>\n",
       "      <th>Households Margin of Error</th>\n",
       "      <th>Households Less Than $10,000</th>\n",
       "      <th>Households Less Than $10,000 Margin of Error</th>\n",
       "      <th>Households $10,000 to $14,999</th>\n",
       "      <th>Households $10,000 to $14,999 Margin of Error</th>\n",
       "      <th>Households $15,000 to $24,999</th>\n",
       "      <th>...</th>\n",
       "      <th>Nonfamily Households $150,000 to $199,999</th>\n",
       "      <th>Nonfamily Households $150,000 to $199,999 Margin of Error</th>\n",
       "      <th>Nonfamily Households $200,000 or More</th>\n",
       "      <th>Nonfamily Households $200,000 or More Margin of Error</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars) Margin of Error</th>\n",
       "      <th>Nonfamily Households Mean Income (Dollars)</th>\n",
       "      <th>Nonfamily Households Mean Income (Dollars) Margin of Error</th>\n",
       "      <th>Nonfamily Households Nonfamily Income in the Past 12 Months</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "      <td>860Z200US00601</td>\n",
       "      <td>ZCTA5 00601</td>\n",
       "      <td>5397.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9386.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>13044.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>860Z200US00602</td>\n",
       "      <td>ZCTA5 00602</td>\n",
       "      <td>12858.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>11242.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>16419.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>860Z200US00603</td>\n",
       "      <td>ZCTA5 00603</td>\n",
       "      <td>19295.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10639.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>16824.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>860Z200US00606</td>\n",
       "      <td>ZCTA5 00606</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>15849.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>16312.0</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>860Z200US00610</td>\n",
       "      <td>ZCTA5 00610</td>\n",
       "      <td>8934.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12832.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>16756.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZIP       Geography Geographic Area Name  Households  \\\n",
       "0  601  860Z200US00601          ZCTA5 00601      5397.0   \n",
       "1  602  860Z200US00602          ZCTA5 00602     12858.0   \n",
       "2  603  860Z200US00603          ZCTA5 00603     19295.0   \n",
       "3  606  860Z200US00606          ZCTA5 00606      1968.0   \n",
       "4  610  860Z200US00610          ZCTA5 00610      8934.0   \n",
       "\n",
       "   Households Margin of Error  Households Less Than $10,000  \\\n",
       "0                       264.0                          33.2   \n",
       "1                       448.0                          27.1   \n",
       "2                       555.0                          32.1   \n",
       "3                       171.0                          28.4   \n",
       "4                       372.0                          20.5   \n",
       "\n",
       "   Households Less Than $10,000 Margin of Error  \\\n",
       "0                                           4.4   \n",
       "1                                           2.9   \n",
       "2                                           2.5   \n",
       "3                                           5.5   \n",
       "4                                           2.5   \n",
       "\n",
       "   Households $10,000 to $14,999  \\\n",
       "0                           15.7   \n",
       "1                           12.7   \n",
       "2                           13.4   \n",
       "3                           13.3   \n",
       "4                           13.2   \n",
       "\n",
       "   Households $10,000 to $14,999 Margin of Error  \\\n",
       "0                                            2.9   \n",
       "1                                            2.1   \n",
       "2                                            1.6   \n",
       "3                                            4.4   \n",
       "4                                            2.5   \n",
       "\n",
       "   Households $15,000 to $24,999  ...  \\\n",
       "0                           23.9  ...   \n",
       "1                           20.5  ...   \n",
       "2                           17.2  ...   \n",
       "3                           23.3  ...   \n",
       "4                           23.3  ...   \n",
       "\n",
       "   Nonfamily Households $150,000 to $199,999  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.6   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   Nonfamily Households $150,000 to $199,999 Margin of Error  \\\n",
       "0                                                2.8           \n",
       "1                                                1.3           \n",
       "2                                                0.6           \n",
       "3                                                7.5           \n",
       "4                                                1.8           \n",
       "\n",
       "   Nonfamily Households $200,000 or More  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.2   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   Nonfamily Households $200,000 or More Margin of Error  \\\n",
       "0                                                2.8       \n",
       "1                                                1.3       \n",
       "2                                                0.4       \n",
       "3                                                7.5       \n",
       "4                                                1.8       \n",
       "\n",
       "   Nonfamily Households Median Income (Dollars)  \\\n",
       "0                                        9386.0   \n",
       "1                                       11242.0   \n",
       "2                                       10639.0   \n",
       "3                                       15849.0   \n",
       "4                                       12832.0   \n",
       "\n",
       "   Nonfamily Households Median Income (Dollars) Margin of Error  \\\n",
       "0                                             1472.0              \n",
       "1                                             1993.0              \n",
       "2                                              844.0              \n",
       "3                                             3067.0              \n",
       "4                                             2405.0              \n",
       "\n",
       "   Nonfamily Households Mean Income (Dollars)  \\\n",
       "0                                     13044.0   \n",
       "1                                     16419.0   \n",
       "2                                     16824.0   \n",
       "3                                     16312.0   \n",
       "4                                     16756.0   \n",
       "\n",
       "   Nonfamily Households Mean Income (Dollars) Margin of Error  \\\n",
       "0                                             1949.0            \n",
       "1                                             2310.0            \n",
       "2                                             2217.0            \n",
       "3                                             2662.0            \n",
       "4                                             1740.0            \n",
       "\n",
       "   Nonfamily Households Nonfamily Income in the Past 12 Months    Year  \n",
       "0                                               15.0            2021.0  \n",
       "1                                               20.1            2021.0  \n",
       "2                                               34.9            2021.0  \n",
       "3                                               13.0            2021.0  \n",
       "4                                               14.5            2021.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income = pd.read_csv('us_income_zipcode.csv')\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c97b50",
   "metadata": {},
   "source": [
    "This dataset contains the results of the 2011 and 2021 national census, and we have chosen it in order to add a median income feature to our real estate pricing dataset. As explained above, we are only interested in the 2021 data since our pricing data comes from recent years, so we will trim down our dataset accordingly. Additionally, the dataset comes with dozens of feature columns, but for our purposes we only need to keep the zip code column (which we will use to merge our original dataset), and the median household income column. So let's process our dataset and display the cleaner result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0114bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "      <td>9386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>11242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>10639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>15849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>12832.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZIP  Nonfamily Households Median Income (Dollars)\n",
       "0  601                                        9386.0\n",
       "1  602                                       11242.0\n",
       "2  603                                       10639.0\n",
       "3  606                                       15849.0\n",
       "4  610                                       12832.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only samples from most recent census\n",
    "df_income = df_income[df_income[\"Year\"] == 2021.0]\n",
    "\n",
    "#select only features we want\n",
    "df_income = df_income[[\"ZIP\", \"Nonfamily Households Median Income (Dollars)\"]]\n",
    "\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56303003",
   "metadata": {},
   "source": [
    "Now we are ready to merge with our original dataset. Currently our zip code columns have different names so we will rename them identically, and they also have different types (integer vs float) so we will convert to a float variable to avoid type error interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7208a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income[\"ZIP\"] = df_income[\"ZIP\"].astype(float)\n",
    "\n",
    "df_income = df_income.rename(columns={'ZIP': 'zip_code'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394f873",
   "metadata": {},
   "source": [
    "We will use an inner merge (explain why...)\n",
    "The census data was very thorough (we have very few NaN values), so we can just remove any empty data rows and our dataset remains practically the same. We verify this assumption by outputting our dataset shape after the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b985056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29948, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>above_average</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1723318.0</td>\n",
       "      <td>Golden Valley</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1236679.0</td>\n",
       "      <td>East Bethel</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48401.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street           city      state  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0       New Hope  Minnesota   \n",
       "1  550000.0  5.0   3.0      0.29  1723318.0  Golden Valley  Minnesota   \n",
       "2  399000.0  4.0   2.0      2.69   559528.0      Oak Grove  Minnesota   \n",
       "3  375000.0  3.0   2.0      1.81  1236679.0    East Bethel  Minnesota   \n",
       "4  394900.0  4.0   3.0      0.24   497833.0   New Brighton  Minnesota   \n",
       "\n",
       "   zip_code  house_size  above_average  \\\n",
       "0   55427.0      2990.0              0   \n",
       "1   55427.0      3137.0              1   \n",
       "2   55011.0      2400.0              1   \n",
       "3   55011.0      1765.0              1   \n",
       "4   55112.0      2107.0              1   \n",
       "\n",
       "   Nonfamily Households Median Income (Dollars)  \n",
       "0                                       46403.0  \n",
       "1                                       46403.0  \n",
       "2                                       69792.0  \n",
       "3                                       69792.0  \n",
       "4                                       48401.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_income, on = [\"zip_code\"])\n",
    "\n",
    "#remove all rows missing data\n",
    "df = df.dropna()\n",
    "\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446b0e0",
   "metadata": {},
   "source": [
    "This feature looks good, let's move on to some more merges.\n",
    "\n",
    "Next, we want to add to our dataset statistics on political affiliation by state and minimum wage by state, which should be slightly simpler than merging by zipcode. \n",
    "\n",
    "First we will use is Kaggle's \"2020 US Presidential Election Results by State\" linked here: https://www.kaggle.com/datasets/callummacpherson14/2020-us-presidential-election-results-by-state. This data was taken appropriately recently to match our real-estate data, and it contains voting percentage and win vs loss data on Biden and Trump from the 2020 election.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70b72055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_abr</th>\n",
       "      <th>trump_pct</th>\n",
       "      <th>biden_pct</th>\n",
       "      <th>trump_vote</th>\n",
       "      <th>biden_vote</th>\n",
       "      <th>trump_win</th>\n",
       "      <th>biden_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>53.1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>189543</td>\n",
       "      <td>153502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>HI</td>\n",
       "      <td>34.3</td>\n",
       "      <td>63.7</td>\n",
       "      <td>196864</td>\n",
       "      <td>366130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington</td>\n",
       "      <td>WA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>58.4</td>\n",
       "      <td>1584651</td>\n",
       "      <td>2369612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>40.7</td>\n",
       "      <td>56.9</td>\n",
       "      <td>958448</td>\n",
       "      <td>1340383</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.3</td>\n",
       "      <td>63.5</td>\n",
       "      <td>5982194</td>\n",
       "      <td>11082293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state state_abr  trump_pct  biden_pct  trump_vote  biden_vote  \\\n",
       "0      Alaska        AK       53.1       43.0      189543      153502   \n",
       "1      Hawaii        HI       34.3       63.7      196864      366130   \n",
       "2  Washington        WA       39.0       58.4     1584651     2369612   \n",
       "3      Oregon        OR       40.7       56.9      958448     1340383   \n",
       "4  California        CA       34.3       63.5     5982194    11082293   \n",
       "\n",
       "   trump_win  biden_win  \n",
       "0          1          0  \n",
       "1          0          1  \n",
       "2          0          1  \n",
       "3          0          1  \n",
       "4          0          1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_election = pd.read_csv('voting.csv.xls')\n",
    "df_election.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0254d",
   "metadata": {},
   "source": [
    "Notice this is quite a clean dataset already, all we need to do is select the columns we are interested in and perform another inner merge along the column column of state. Here, we will choose to keep the state column which is needed for the merge, as well as the Trump pct, Biden pct columns since these provide more detailed information then the binary win vs loss columns. Let's do so and check our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "755c8900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have: 0 NaN entires\n",
      "(29948, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>above_average</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "      <th>biden_pct</th>\n",
       "      <th>trump_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1723318.0</td>\n",
       "      <td>Golden Valley</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1236679.0</td>\n",
       "      <td>East Bethel</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48401.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street           city      state  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0       New Hope  Minnesota   \n",
       "1  550000.0  5.0   3.0      0.29  1723318.0  Golden Valley  Minnesota   \n",
       "2  399000.0  4.0   2.0      2.69   559528.0      Oak Grove  Minnesota   \n",
       "3  375000.0  3.0   2.0      1.81  1236679.0    East Bethel  Minnesota   \n",
       "4  394900.0  4.0   3.0      0.24   497833.0   New Brighton  Minnesota   \n",
       "\n",
       "   zip_code  house_size  above_average  \\\n",
       "0   55427.0      2990.0              0   \n",
       "1   55427.0      3137.0              1   \n",
       "2   55011.0      2400.0              1   \n",
       "3   55011.0      1765.0              1   \n",
       "4   55112.0      2107.0              1   \n",
       "\n",
       "   Nonfamily Households Median Income (Dollars)  biden_pct  trump_pct  \n",
       "0                                       46403.0       52.6       45.4  \n",
       "1                                       46403.0       52.6       45.4  \n",
       "2                                       69792.0       52.6       45.4  \n",
       "3                                       69792.0       52.6       45.4  \n",
       "4                                       48401.0       52.6       45.4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only features we want\n",
    "df_election = df_election[[\"state\", \"biden_pct\", \"trump_pct\"]]\n",
    "\n",
    "#merge dataframe along the column of state\n",
    "df = pd.merge(df, df_election, on = [\"state\"])\n",
    "\n",
    "#verify there were no null data values added\n",
    "print (f'We still have: {df.isnull().sum().sum()} NaN entires')\n",
    "\n",
    "#output model summary\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741de9f7",
   "metadata": {},
   "source": [
    "Notice we still have no NaN entries, so our merging didn't add any problematic data and appears to be successfully added. \n",
    "\n",
    "Finally, we will perform this process one more time in order to add data on what each state's minimum wage is. This time we will use Kaggle's \"Living Wage - State Capitals\" found at https://www.kaggle.com/datasets/brandonconrady/living-wage-state-capitals. We again verified this was taken from the past two years for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "823db446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_territory</th>\n",
       "      <th>city</th>\n",
       "      <th>minimum_wage</th>\n",
       "      <th>one_adult_no_kids_living_wage</th>\n",
       "      <th>one_adult_one_kid_living_wage</th>\n",
       "      <th>one_adult_two_kids_living_wage</th>\n",
       "      <th>one_adult_three_kids_living_wage</th>\n",
       "      <th>two_adults_one_working_no_kids_living_wage</th>\n",
       "      <th>two_adults_one_working_one_kid_living_wage</th>\n",
       "      <th>two_adults_one_working_two_kids_living_wage</th>\n",
       "      <th>...</th>\n",
       "      <th>one_adult_two_kids_poverty_wage</th>\n",
       "      <th>one_adult_three_kids_poverty_wage</th>\n",
       "      <th>two_adults_one_working_no_kids_poverty_wage</th>\n",
       "      <th>two_adults_one_working_one_kid_poverty_wage</th>\n",
       "      <th>two_adults_one_working_two_kids_poverty_wage</th>\n",
       "      <th>two_adults_one_working_three_kids_poverty_wage</th>\n",
       "      <th>two_adults_both_working_no_kids_poverty_wage</th>\n",
       "      <th>two_adults_both_working_one_kid_poverty_wage</th>\n",
       "      <th>two_adults_both_working_two_kids_poverty_wage</th>\n",
       "      <th>two_adults_both_working_three_kids_poverty_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Washington</td>\n",
       "      <td>13.25</td>\n",
       "      <td>19.97</td>\n",
       "      <td>38.95</td>\n",
       "      <td>48.99</td>\n",
       "      <td>63.96</td>\n",
       "      <td>29.61</td>\n",
       "      <td>34.55</td>\n",
       "      <td>38.32</td>\n",
       "      <td>...</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8.29</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>7.25</td>\n",
       "      <td>13.56</td>\n",
       "      <td>27.35</td>\n",
       "      <td>33.42</td>\n",
       "      <td>42.17</td>\n",
       "      <td>22.59</td>\n",
       "      <td>26.66</td>\n",
       "      <td>30.27</td>\n",
       "      <td>...</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8.29</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>10.19</td>\n",
       "      <td>15.48</td>\n",
       "      <td>29.99</td>\n",
       "      <td>36.00</td>\n",
       "      <td>47.42</td>\n",
       "      <td>24.48</td>\n",
       "      <td>29.46</td>\n",
       "      <td>33.01</td>\n",
       "      <td>...</td>\n",
       "      <td>13.05</td>\n",
       "      <td>15.75</td>\n",
       "      <td>10.36</td>\n",
       "      <td>13.05</td>\n",
       "      <td>15.75</td>\n",
       "      <td>18.44</td>\n",
       "      <td>5.18</td>\n",
       "      <td>6.53</td>\n",
       "      <td>7.87</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.41</td>\n",
       "      <td>29.44</td>\n",
       "      <td>35.40</td>\n",
       "      <td>46.01</td>\n",
       "      <td>24.85</td>\n",
       "      <td>29.25</td>\n",
       "      <td>32.98</td>\n",
       "      <td>...</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8.29</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.97</td>\n",
       "      <td>28.81</td>\n",
       "      <td>35.49</td>\n",
       "      <td>45.33</td>\n",
       "      <td>23.21</td>\n",
       "      <td>27.66</td>\n",
       "      <td>31.36</td>\n",
       "      <td>...</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8.29</td>\n",
       "      <td>10.44</td>\n",
       "      <td>12.60</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_territory         city  minimum_wage  \\\n",
       "0  District of Columbia   Washington         13.25   \n",
       "1               Alabama   Montgomery          7.25   \n",
       "2                Alaska       Juneau         10.19   \n",
       "3               Arizona      Phoenix         12.00   \n",
       "4              Arkansas  Little Rock         10.00   \n",
       "\n",
       "   one_adult_no_kids_living_wage  one_adult_one_kid_living_wage  \\\n",
       "0                          19.97                          38.95   \n",
       "1                          13.56                          27.35   \n",
       "2                          15.48                          29.99   \n",
       "3                          15.41                          29.44   \n",
       "4                          13.97                          28.81   \n",
       "\n",
       "   one_adult_two_kids_living_wage  one_adult_three_kids_living_wage  \\\n",
       "0                           48.99                             63.96   \n",
       "1                           33.42                             42.17   \n",
       "2                           36.00                             47.42   \n",
       "3                           35.40                             46.01   \n",
       "4                           35.49                             45.33   \n",
       "\n",
       "   two_adults_one_working_no_kids_living_wage  \\\n",
       "0                                       29.61   \n",
       "1                                       22.59   \n",
       "2                                       24.48   \n",
       "3                                       24.85   \n",
       "4                                       23.21   \n",
       "\n",
       "   two_adults_one_working_one_kid_living_wage  \\\n",
       "0                                       34.55   \n",
       "1                                       26.66   \n",
       "2                                       29.46   \n",
       "3                                       29.25   \n",
       "4                                       27.66   \n",
       "\n",
       "   two_adults_one_working_two_kids_living_wage  ...  \\\n",
       "0                                        38.32  ...   \n",
       "1                                        30.27  ...   \n",
       "2                                        33.01  ...   \n",
       "3                                        32.98  ...   \n",
       "4                                        31.36  ...   \n",
       "\n",
       "   one_adult_two_kids_poverty_wage  one_adult_three_kids_poverty_wage  \\\n",
       "0                            10.44                              12.60   \n",
       "1                            10.44                              12.60   \n",
       "2                            13.05                              15.75   \n",
       "3                            10.44                              12.60   \n",
       "4                            10.44                              12.60   \n",
       "\n",
       "   two_adults_one_working_no_kids_poverty_wage  \\\n",
       "0                                         8.29   \n",
       "1                                         8.29   \n",
       "2                                        10.36   \n",
       "3                                         8.29   \n",
       "4                                         8.29   \n",
       "\n",
       "   two_adults_one_working_one_kid_poverty_wage  \\\n",
       "0                                        10.44   \n",
       "1                                        10.44   \n",
       "2                                        13.05   \n",
       "3                                        10.44   \n",
       "4                                        10.44   \n",
       "\n",
       "   two_adults_one_working_two_kids_poverty_wage  \\\n",
       "0                                         12.60   \n",
       "1                                         12.60   \n",
       "2                                         15.75   \n",
       "3                                         12.60   \n",
       "4                                         12.60   \n",
       "\n",
       "   two_adults_one_working_three_kids_poverty_wage  \\\n",
       "0                                           14.75   \n",
       "1                                           14.75   \n",
       "2                                           18.44   \n",
       "3                                           14.75   \n",
       "4                                           14.75   \n",
       "\n",
       "   two_adults_both_working_no_kids_poverty_wage  \\\n",
       "0                                          4.14   \n",
       "1                                          4.14   \n",
       "2                                          5.18   \n",
       "3                                          4.14   \n",
       "4                                          4.14   \n",
       "\n",
       "   two_adults_both_working_one_kid_poverty_wage  \\\n",
       "0                                          5.22   \n",
       "1                                          5.22   \n",
       "2                                          6.53   \n",
       "3                                          5.22   \n",
       "4                                          5.22   \n",
       "\n",
       "   two_adults_both_working_two_kids_poverty_wage  \\\n",
       "0                                           6.30   \n",
       "1                                           6.30   \n",
       "2                                           7.87   \n",
       "3                                           6.30   \n",
       "4                                           6.30   \n",
       "\n",
       "   two_adults_both_working_three_kids_poverty_wage  \n",
       "0                                             7.38  \n",
       "1                                             7.38  \n",
       "2                                             9.22  \n",
       "3                                             7.38  \n",
       "4                                             7.38  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minwage = pd.read_csv('LivingWageStateCapitals.csv.xls')\n",
    "df_minwage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ffb80",
   "metadata": {},
   "source": [
    "Again, we want to select the columns we need which in this case is the state column to merge along and the minimum_wage column which has the minimum wage data we desire (in dollars). Here, we will also rename the \"state_territory\" column to have the same title \"state\" as our original dataframe to streamline the merging process. Then after we complete the inner merge we will verify our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "335cd874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still have: 0 NaN entires\n",
      "(29948, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>above_average</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "      <th>biden_pct</th>\n",
       "      <th>trump_pct</th>\n",
       "      <th>minimum_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>New Hope</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1723318.0</td>\n",
       "      <td>Golden Valley</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1236679.0</td>\n",
       "      <td>East Bethel</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>New Brighton</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48401.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>45.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street           city      state  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0       New Hope  Minnesota   \n",
       "1  550000.0  5.0   3.0      0.29  1723318.0  Golden Valley  Minnesota   \n",
       "2  399000.0  4.0   2.0      2.69   559528.0      Oak Grove  Minnesota   \n",
       "3  375000.0  3.0   2.0      1.81  1236679.0    East Bethel  Minnesota   \n",
       "4  394900.0  4.0   3.0      0.24   497833.0   New Brighton  Minnesota   \n",
       "\n",
       "   zip_code  house_size  above_average  \\\n",
       "0   55427.0      2990.0              0   \n",
       "1   55427.0      3137.0              1   \n",
       "2   55011.0      2400.0              1   \n",
       "3   55011.0      1765.0              1   \n",
       "4   55112.0      2107.0              1   \n",
       "\n",
       "   Nonfamily Households Median Income (Dollars)  biden_pct  trump_pct  \\\n",
       "0                                       46403.0       52.6       45.4   \n",
       "1                                       46403.0       52.6       45.4   \n",
       "2                                       69792.0       52.6       45.4   \n",
       "3                                       69792.0       52.6       45.4   \n",
       "4                                       48401.0       52.6       45.4   \n",
       "\n",
       "   minimum_wage  \n",
       "0          10.0  \n",
       "1          10.0  \n",
       "2          10.0  \n",
       "3          10.0  \n",
       "4          10.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only features we want\n",
    "df_minwage = df_minwage[[\"state_territory\", \"minimum_wage\"]]\n",
    "\n",
    "#rename state_territory column\n",
    "df_minwage = df_minwage.rename(columns={'state_territory': 'state'})\n",
    "\n",
    "#merge dataframe along the column of state\n",
    "df = pd.merge(df, df_minwage, on = [\"state\"])\n",
    "\n",
    "#verify there were no null data values added\n",
    "print (f'We still have: {df.isnull().sum().sum()} NaN entires')\n",
    "\n",
    "#output model summary\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca62197",
   "metadata": {},
   "source": [
    "Now we are officially done with merging our dataset and have plenty of new columns to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9530015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving this version of the data to the files on my computer so \n",
    "## I don't have to run all the above again\n",
    "\n",
    "# df.to_csv('clean_merged_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96c63b",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "(Just writing some notes for us to use later)\n",
    "- maybe create a fancy visual heatmap type thing showing our prices by zipcode on the us map\n",
    "- Create bar plots, histograms, correlation plots etc using tangible factors from our og dataset (room number, acres etc) should show clear trend\n",
    "- Same thing but for some intangible factors using newly merged data, see if we can come to cool conclusions about those correlations\n",
    "- Writeup analysis about what this shows us about society/housing market"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c258a0e8-9eca-4f81-a0f0-5654903c5f66",
   "metadata": {},
   "source": [
    "## Prep For Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "614ce8b8-b2b8-474b-8491-fc3e22a0e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb210ea-d1b0-44fa-abcc-07b760104d6a",
   "metadata": {},
   "source": [
    "Our code uses categorical, non-numerical columns, which doesnt work with PCA. To allow us to use dimesnion reduction tecniques such as PCA or kernel PCA, we must assign our categorical names into binary through using one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce11cf5-6f3d-41e5-b624-6e0d3d1c4d5e",
   "metadata": {},
   "source": [
    "To determine which columns we need to use hot encoding on, we need to check which columns are categorical and which are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b53b6837-52d7-4f42-b8d3-42bbb81d2e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['price', 'bed', 'bath', 'acre_lot', 'street', 'zip_code', 'house_size', 'above_average', 'Nonfamily Households Median Income (Dollars)', 'biden_pct', 'trump_pct', 'minimum_wage']\n",
      "Categorical columns: ['city', 'state']\n"
     ]
    }
   ],
   "source": [
    "# create lists to hold the names of the numeric and categorical cols\n",
    "num_cols = []\n",
    "categorical_cols = []\n",
    "\n",
    "# loop through the columns of the dataframe, if the type of the column is int or float, it is numeric. if not, it is categorical\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "        num_cols.append(col)\n",
    "    else:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "print('Numeric columns:', num_cols)\n",
    "print('Categorical columns:', categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cf65b49-b970-45cc-9b24-e572d548eca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 19:33:02.821044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>above_average</th>\n",
       "      <th>Nonfamily Households Median Income (Dollars)</th>\n",
       "      <th>biden_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>state_South Dakota</th>\n",
       "      <th>state_Tennessee</th>\n",
       "      <th>state_Texas</th>\n",
       "      <th>state_Utah</th>\n",
       "      <th>state_Vermont</th>\n",
       "      <th>state_Virginia</th>\n",
       "      <th>state_Washington</th>\n",
       "      <th>state_West Virginia</th>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <th>state_Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1728557.0</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1723318.0</td>\n",
       "      <td>55427.0</td>\n",
       "      <td>3137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>559528.0</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1236679.0</td>\n",
       "      <td>55011.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>497833.0</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48401.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bed  bath  acre_lot     street  zip_code  house_size  \\\n",
       "0  300000.0  3.0   2.0      0.32  1728557.0   55427.0      2990.0   \n",
       "1  550000.0  5.0   3.0      0.29  1723318.0   55427.0      3137.0   \n",
       "2  399000.0  4.0   2.0      2.69   559528.0   55011.0      2400.0   \n",
       "3  375000.0  3.0   2.0      1.81  1236679.0   55011.0      1765.0   \n",
       "4  394900.0  4.0   3.0      0.24   497833.0   55112.0      2107.0   \n",
       "\n",
       "   above_average  Nonfamily Households Median Income (Dollars)  biden_pct  \\\n",
       "0              0                                       46403.0       52.6   \n",
       "1              1                                       46403.0       52.6   \n",
       "2              1                                       69792.0       52.6   \n",
       "3              1                                       69792.0       52.6   \n",
       "4              1                                       48401.0       52.6   \n",
       "\n",
       "   ...  state_South Dakota  state_Tennessee  state_Texas  state_Utah  \\\n",
       "0  ...                   0                0            0           0   \n",
       "1  ...                   0                0            0           0   \n",
       "2  ...                   0                0            0           0   \n",
       "3  ...                   0                0            0           0   \n",
       "4  ...                   0                0            0           0   \n",
       "\n",
       "   state_Vermont  state_Virginia  state_Washington  state_West Virginia  \\\n",
       "0              0               0                 0                    0   \n",
       "1              0               0                 0                    0   \n",
       "2              0               0                 0                    0   \n",
       "3              0               0                 0                    0   \n",
       "4              0               0                 0                    0   \n",
       "\n",
       "   state_Wisconsin  state_Wyoming  \n",
       "0                0              0  \n",
       "1                0              0  \n",
       "2                0              0  \n",
       "3                0              0  \n",
       "4                0              0  \n",
       "\n",
       "[5 rows x 6166 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import KernelPCA\n",
    "## THIS IS THE WAY THE OTHER 16 PROJECT DID IT\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# one hot encode categorical features\n",
    "one_hot_encoded_data = pd.get_dummies(data, columns = ['city', 'state'])\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "one_hot_encoded_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d39a81-3ab4-411f-80c5-67443e173abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into test/train data\n",
    "X = one_hot_encoded_data.drop(['above_average'], axis = 1)\n",
    "y = one_hot_encoded_data['above_average']\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Scale the numeric features before converting to arrays\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "scaler = StandardScaler()\n",
    "train_X[numeric_features] = scaler.fit_transform(train_X[numeric_features])\n",
    "test_X[numeric_features] = scaler.transform(test_X[numeric_features])\n",
    "\n",
    "# Convert to arrays for the model\n",
    "X_train = np.array(train_X, dtype=np.float32)\n",
    "X_test = np.array(test_X, dtype=np.float32)\n",
    "y_train = tf.keras.utils.to_categorical(train_y).astype(np.int64)\n",
    "y_test = tf.keras.utils.to_categorical(test_y).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4748c14-dbc5-4d5b-aa13-06398f439741",
   "metadata": {},
   "source": [
    "## Data Processing for Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70025ba5-df2d-40c8-9aea-80830a0a607e",
   "metadata": {},
   "source": [
    "Label encoding to further simplify number of columns for kernel pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bc40a019-24c9-4fd0-98eb-476f3488af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "# create the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# create the label encoded data and split it into train and test sets. we set the random state to be the same for all train test splits\n",
    "# so we know our results are from the same data.\n",
    "label_encoded_data = df.copy()\n",
    "label_encoded_data['state'] = label_encoder.fit_transform(label_encoded_data['state'])\n",
    "label_encoded_data['city'] = label_encoder.fit_transform(label_encoded_data['city'])\n",
    "\n",
    "# create X and y data\n",
    "X_le = label_encoded_data.drop(['above_average'], axis=1)\n",
    "y_le = label_encoded_data['above_average']\n",
    "\n",
    "# split into train and test sets\n",
    "train_Xle, test_Xle, train_yle, test_yle = train_test_split(X_le, y_le, test_size=0.33, random_state=42)\n",
    "\n",
    "# scale the numeric features\n",
    "scaler = StandardScaler()\n",
    "train_Xle = scaler.fit_transform(train_Xle)\n",
    "test_Xle = scaler.transform(test_Xle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748d484-ffe8-49d5-a7e8-2a330345a794",
   "metadata": {},
   "source": [
    "Need to do grid search to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dcb262a-0dc7-413e-8048-cbd7f851902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.809 total time=  53.6s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.809 total time=  53.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.811 total time=  52.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.805 total time=  52.4s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.810 total time=  50.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.872 total time=  32.8s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.867 total time=  32.5s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.867 total time=  32.4s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.866 total time=  32.7s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.867 total time=  32.7s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.827 total time=  37.7s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.824 total time=  37.6s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.823 total time=  37.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.823 total time=  37.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.826 total time=  37.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.779 total time=  45.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.775 total time=  45.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.778 total time=  45.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.775 total time=  45.5s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.781 total time=  45.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.599 total time=  56.8s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.600 total time=  57.9s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.597 total time=  57.8s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.598 total time=  58.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.595 total time=  56.7s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.867 total time= 1.2min\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.864 total time= 1.2min\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.869 total time= 1.1min\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.866 total time= 1.1min\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.865 total time= 1.1min\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.932 total time=  22.8s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.930 total time=  22.6s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.931 total time=  22.4s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.932 total time=  22.5s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.932 total time=  22.5s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.896 total time=  28.3s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.894 total time=  28.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.895 total time=  28.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.894 total time=  27.9s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.894 total time=  27.9s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.827 total time=  36.9s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.826 total time=  36.8s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.826 total time=  36.9s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.822 total time=  36.9s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.828 total time=  37.1s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.779 total time=  45.1s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.775 total time=  44.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.778 total time=  45.8s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.775 total time=  44.7s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.780 total time=  45.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.901 total time= 1.8min\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.898 total time= 1.6min\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.900 total time= 1.6min\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.897 total time= 1.8min\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.902 total time= 1.8min\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.962 total time=  17.7s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.959 total time=  17.3s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=  17.7s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.959 total time=  17.3s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.963 total time=  17.7s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.923 total time=  20.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.922 total time=  19.6s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.921 total time=  19.8s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.927 total time=  19.7s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.927 total time=  20.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.886 total time=  28.4s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.883 total time=  28.2s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.888 total time=  28.5s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.883 total time=  28.2s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.888 total time=  28.6s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.826 total time=  36.9s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.826 total time=  37.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.825 total time=  37.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.820 total time=  37.4s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.827 total time=  37.2s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.905 total time= 1.8min\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.903 total time= 1.8min\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.904 total time= 1.6min\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.904 total time= 1.8min\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.907 total time= 1.6min\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.971 total time=  19.6s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.971 total time=  19.9s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.972 total time=  18.7s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.970 total time=  19.4s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.974 total time=  19.7s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=  18.8s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.935 total time=  18.5s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.932 total time=  18.6s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.939 total time=  18.5s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.940 total time=  18.7s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.906 total time=  21.4s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.909 total time=  21.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.908 total time=  21.7s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.910 total time=  21.7s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.910 total time=  22.3s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.877 total time=  28.7s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.874 total time=  28.4s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.878 total time=  29.2s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.872 total time=  28.8s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.880 total time=  28.4s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.908 total time= 1.7min\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.904 total time= 1.7min\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.905 total time= 1.8min\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.906 total time= 1.7min\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.909 total time= 1.8min\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.975 total time=  31.2s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.973 total time=  33.5s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.973 total time=  34.5s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.973 total time=  32.2s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.976 total time=  32.9s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.950 total time=  29.3s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.950 total time=  30.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.947 total time=  30.4s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.949 total time=  29.9s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.954 total time=  30.8s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.922 total time=  22.1s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.922 total time=  22.3s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.920 total time=  22.5s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.923 total time=  21.6s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.926 total time=  21.9s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.893 total time=  22.8s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.895 total time=  23.2s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.897 total time=  23.5s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.894 total time=  23.3s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.898 total time=  23.3s\n",
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(train_Xle, train_yle)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1e31823-1073-41a3-84d1-3105d3dd6b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is 0.9319536917420252.\n",
      "The evaluation score is 0.8817209724604055.\n"
     ]
    }
   ],
   "source": [
    "# create SVM model and train\n",
    "svc = SVC(kernel='rbf', C=1, gamma=1)\n",
    "svc.fit(train_Xle, train_yle)\n",
    "\n",
    "# score model on training and test data\n",
    "score = svc.score(test_Xle, test_yle)\n",
    "svm_train_score = svc.score(train_Xle, train_yle)\n",
    "svm_preds = svc.predict(test_Xle)\n",
    "\n",
    "# print scores\n",
    "print(f'The training score is {svm_train_score}.')\n",
    "print(f'The evaluation score is {score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f77b0-6f09-4d88-989c-6dffb146be0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kernel PCA to Create New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40962c9-c5f0-4cae-82dc-6c779134be5f",
   "metadata": {},
   "source": [
    "\"In attempt to get our accuracy score up, we will perform Kernel PCA on our data to hopefully create better features to train on our models and make them more accurate.\n",
    "Kernel PCA is a nonlinear dimensionality reduction method. It applies a nonlinear mapping function to the data before applying PCA, which lets it capture more complex \n",
    "and nonlinear relationships between the data. We choose n_components = 2 because otherwise our runtime would crash. We thought that since Kernel PCA can be more robust \n",
    "to outliers and noise in the data and it captures global structures in the data, that it might help us classify songs better if we use the new features that are created \n",
    "by it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "226299e0-6838-4e64-b037-45f58d4ba940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.01, solver=&#x27;newton-cg&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, solver='newton-cg')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the KPCA, fit and transform our data based on new features\n",
    "kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
    "kpca_train_Xle = kpca.fit_transform(train_Xle)\n",
    "kpca_test_Xle = kpca.transform(test_Xle)\n",
    "\n",
    "# create and fit Logistic Regression model on the new features\n",
    "lr_kpca = LogisticRegression(C=0.01, penalty= 'l2', solver='newton-cg')\n",
    "lr_kpca.fit(train_Xle, train_yle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a97a894-3766-419f-9765-d7cf657f1100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a05ac84c-8b6d-4b00-8f5f-0eaa38686881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508019772016544"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score model on the test data\n",
    "y_pred = lr_kpca.predict(test_Xle)\n",
    "accuracy_score(test_yle, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592816bd-6ccf-48de-bf99-65b12c8a28a6",
   "metadata": {},
   "source": [
    "# Discussion of these origional models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859bac9-7968-4f25-9f87-210487aa588c",
   "metadata": {},
   "source": [
    "# Genre Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9ba00-adac-4304-a858-0453c0889c43",
   "metadata": {},
   "source": [
    "## Data Processing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738c118-8e91-4fed-80dd-232308148c2b",
   "metadata": {},
   "source": [
    "## Preparing NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10985050-5ac6-4cd6-b4ca-16cb2a56227f",
   "metadata": {},
   "source": [
    "## New NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf13c0d-ff92-4f28-bff5-b4dfe2a635a9",
   "metadata": {},
   "source": [
    "# Neural Network On Label Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf537a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note from Olivia:\n",
    "## don't want to have to rerun all of the above each time so saved testing and training arrays in my files\n",
    "\n",
    "# np.save('train_Xle.npy', train_Xle) \n",
    "# np.save('test_Xle.npy', test_Xle) \n",
    "# np.save('train_yle.npy', train_yle) \n",
    "# np.save('test_yle.npy', test_yle) \n",
    "\n",
    "## How to load the saved array from the file \n",
    "# train_Xle = np.load('train_Xle.npy') \n",
    "# test_Xle = np.load('test_Xle.npy') \n",
    "# train_yle = np.load('train_yle.npy') \n",
    "# test_yle = np.load('test_yle.npy') \n",
    "\n",
    "## print the loaded array \n",
    "# print(train_Xle) \n",
    "# print(test_Xle) \n",
    "# print(train_yle) \n",
    "# print(test_yle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bec3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a25ec9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20065, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data: train_Xle, test_Xle, train_yle, test_yle = train_test_split(X_le, y_le, test_size=0.33, random_state=42)\n",
    "\n",
    "# 11 features for the model\n",
    "train_Xle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6813121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.544829\n",
       "1    0.455171\n",
       "Name: above_average, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_yle.value_counts() / len(train_yle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978bf12",
   "metadata": {},
   "source": [
    "Before starting, I just wanted to check that there is an approximatley even split between the number of above/below state median samples in our training data and there is. This tells us that the data we are using to train the model is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4afaa4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Xle[0]), len(train_yle.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ae2e8146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Xle.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac4ec0",
   "metadata": {},
   "source": [
    "Looking at the above, there will be 13 input neurons and 2 output neurons for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39daa3ae",
   "metadata": {},
   "source": [
    "## Creating a Model Using Keras Sequential API  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95103e",
   "metadata": {},
   "source": [
    "### Number of Neurons in Hidden Layer Determination\n",
    "\n",
    "To determine the number of neurons in each hidden layer, I used the 2/3 rule from this link: https://medium.com/geekculture/introduction-to-neural-network-2f8b8221fbd3.\n",
    "\n",
    "The input is 13 neurons plus the 2 output neurons and 2/3 of the sum is 10.\n",
    "\n",
    "The initial dropout value is 0.2 (ref:  https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/#:~:text=Tips%20for%20Using%20Dropout&text=Generally%2C%20use%20a%20small%20dropout,providing%20a%20good%20starting%20point.) and will be altered to something between 0.2-0.5 to help with overfitting.\n",
    "\n",
    "### Compiling the Model\n",
    "\"The loss function used for binary classification problems is determined by the data format as well. When dealing with a single target vector of 0s and 1s, you should use BinaryCrossentropy as the loss function. When your target variable is stored as One-Hot-Encoded values, you should use the CategoricalCrossentropy loss function.\"\n",
    "(ref:https://www.enthought.com/blog/neural-network-output-layer/#:~:text=For%20the%20binary%20classification%20case,used%20in%20the%20output%20layer.)\n",
    "\n",
    "`adam` was used for the optimizer according to it's success on other models and the fact that it is widely utilized. (ref: https://arxiv.org/pdf/1412.6980)\n",
    "\n",
    "### Fitting the Model\n",
    "\n",
    "For training, the number of epochs was set to 11 since (ref:https://datascientest.com/en/epoch-an-essential-notion#:~:text=Generally%2C%20a%20number%20of%2011,to%20optimally%20modify%20the%20weights.) generally found that \"11 epochs is ideal for training on most datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c719d594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6620 - loss: 0.6095\n",
      "Epoch 2/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7621 - loss: 0.4666\n",
      "Epoch 3/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4220\n",
      "Epoch 4/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3855\n",
      "Epoch 5/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3400\n",
      "Epoch 6/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3241\n",
      "Epoch 7/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3214\n",
      "Epoch 8/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.2961\n",
      "Epoch 9/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2942\n",
      "Epoch 10/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.2829\n",
      "Epoch 11/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2803\n"
     ]
    }
   ],
   "source": [
    "# setting a seed for reproducability \n",
    "tf.random.set_seed(555)\n",
    "\n",
    "# Creating the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    # defining hidden layer\n",
    "    layers.Dense(10, activation = 'relu', kernel_initializer = \"he_normal\", input_shape = (train_Xle.shape[1],)), \n",
    "    \n",
    "    # dropout layer \n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # output layer 1 neuron\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy'] \n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "model_1_hist = model_1.fit(train_Xle, train_yle, epochs = 11, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22497697",
   "metadata": {},
   "source": [
    "### Plotting Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dc2eab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training Accuracy')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsf0lEQVR4nO3deXxV9Z3/8deHsCZhJyBL2BHFjSWyqGNVakWnSqlV0ZaqVdGOttrpz6X9zW/GmU5nnKpdHqOtokVREVTUitVxGcexroSA7IiGLQkECFsIgZDt8/vjnuBtzHIDObm5ue/n43Ef955zvt9zP0dDPvl+v+f7PebuiIiIxKpdvAMQEZHEosQhIiJNosQhIiJNosQhIiJNosQhIiJN0j7eAbSEPn36+NChQ+MdhohIQlm2bNlud8+ovT8pEsfQoUPJycmJdxgiIgnFzLbWtV9dVSIi0iRKHCIi0iRKHCIi0iRKHCIi0iRKHCIi0iRKHCIi0iRKHCIi0iRJMY9DRCRZlFVUsbHoILm7DvLFzoNcdWYmmb1Sm/U7lDhERBJQSVlFJDnsOsjG4D1310Hy9x2i5jFLKe2MCUN6KnGIiCSTvaXlQYIo4YudB9lYFGlJ7DhQdrRMx5R2DM9I4/RB3bl8/CBG9k1nVL90hvROpVP7lGaPSYlDRCTO3J1dJUf4YudBcneV8EVUS2JPafnRcqkdUxjZN52zRvaOJIe+XRnZN53Mnl1on9JyQ9ZKHCIiLaS62tm2//DRFkRNV1PuzoOUHKk8Wq57lw6M6pvOhWP6MbJvetCC6Er/bp1p187ieAURShwiIsfA3TlUXsXBI5WUlFVSeqTy6OeDRyo5WFYReT9SxY7iw+QGA9ZlFdVHz5HRtRMjM9KZMX7glwmib1f6pHfELP4Joj5KHCKSVCqqqjlY88u95lVWSUnwXnrky88Hj1T8VTIojSpbeqSSam/8+zq2b0dGeidG9k1n0qTejAoSxMi+6fRI7Rj+BYdAiUNE2qTiwxWsLihmZcF+VuTvZ822YvaWlnOksrrxykB6p/aRV+fIe9fO7enXtfNfbUcfjy7ftVMH0ju3J61TSiiD0/GmxCEiCe9IZRXrC0tYmb+flfn7WVGwn01FpUePD89IY9KwXvTr1pn0Tu1JO/oLvn2tRNCBtE4ppHVs3yrGElorJQ4RSSjV1c6m3aWRJFEQSRTrCg9QURXpN+qT3omxmT349riBnJHZg9MH9aB7lw5xjrptCTVxmNk04HdACvC4u99X63h34BlgcBDLA+7+hJmNBp6LKjoc+Ed3/62Z3QvcBBQFx37u7q+HeR0iEj+7DpTxadCSWFmwn1X5xUfvQErrmMJpg7rzg3OGMXZQD87I7EH/7p1b9cByWxBa4jCzFOBh4EKgAFhqZovdfV1UsVuBde5+qZllABvMbL67bwDGRp1nG/ByVL3fuPsDYcUuIvFRUlbB6m3FrMwvPpooCosjE93atzNO6t+Vy8YO4IzMHozN7MGIjHRS1KXU4sJscUwEct19E4CZLQSmA9GJw4GuFvnzIB3YC1TWOs9UYKO71/nsWxFJTOWV1WzYUcKKoLtpZf5+cosOHl0uY2jvVCYO68UZQUvilAHd6Nyh7Q00J6IwE8dAID9quwCYVKvMQ8BiYDvQFbjK3Wvf8jATWFBr321m9n0gB/ipu++r/eVmNhuYDTB48OBjvQYROU41s6I37y5l8+5SNuwoYWXBftZuP0B5cIdT77SOjM3swaVnRFoTpw/sTs+0xLxVNRmEmTjqaj/Wvuv5ImAFcAEwAnjbzN539wMAZtYRuAz4WVSdPwC/CM71C+BB4Adf+SL3OcAcgKysrBjuthaRY+Xu7DtUcTQ5bAneN+8uZcueUg6VVx0t26VDCqcN7M61U4Yc7XIa2KOLxiUSSJiJowDIjNoeRKRlEe164D53dyDXzDYDJwHZwfGLgeXuvrOmQvRnM3sM+HMIsYtIHUrKKtiy+xCbdh9ky+5DbN59kM17DrG56CAHyr7sZU5pZ2T27MKwPmlMGt6LYX3SGNYnjaG90xjQo4vGJRJcmIljKTDKzIYRGdyeCVxTq0wekTGM982sHzAa2BR1/GpqdVOZWX93Lww2ZwBrQohdJGkdLq9iy56g1bCnlM1FkVbD5t2l7D745YJ7ZjCgeyQ5XDZ2AEN7pzE8I5IcMnul0qEFF92TlhVa4nD3SjO7DXiTyO24c919rZndEhx/hEhX05NmtppI19bd7r4bwMxSidyRdXOtU//KzMYS6araUsdxEWlERVU1eXsPHU0Km6K6l2ruYqqR0bUTw/qkMfWkfgwNWg7D+qQxpHeqBquTlLm3/e7/rKwsz8nJiXcYInHl7uRs3ceinAJeW13IwajVWHukdogkhN5Bl1KfL9/TO2mecLIys2XunlV7v34iRNq4bfsP89KyAhYtL2DrnkOkdkzhktP6c9aI3pEE0TtNdzBJkyhxiLRBh8ureGNtIYuWFfDRxj24w5ThvfnxBaOYduoJpKkVIcdBPz0ibURdXVGZvbpwx9QT+fb4gc3+3GlJXkocIgmupivqxeUFbInqivrOhEFMHNpLq7xKs1PiEElAh8ureHPtDhYtK+DDjbtxh8nDe3HbBaO4WF1REjL9dIkkCHdn2dZ9LFpWwJ9XRbqiBvXswu1TR3H5+EHqipIWo8Qh0spt23+Yl5cXsGiZuqKkdVDiEGmF6uqKmjSsF7eeP5JLTuuvriiJK/30ibQS7s7yvKAramUhJUFX1I8viHRFDe6trihpHZQ4ROJs+/7DvPzpNhYtK2Dz7lK6dPiyK2rSMHVFSeujxCESB5VV1by9bifPZufxQe6XXVF/d94ILj6tv5b5kFZNP50iLWhvaTkLsvOY/8lWtheXMbBHF350wSguHz+QIb3T4h2eSEyUOERawJptxTz50RYWr9xOeWU1Z43ozT9ddgpfP7mfnk0hCUeJQyQkFVXV/NeaHcz7aAvLtu6jS4cUrpgwiGvPGsqJ/brGOzyRY6bEIdLMikqO8OySPOYv2cqukiMM6Z3KP/ztyVyRlUn3Lh3iHZ7IcVPiEGkmn+btY95HW3htdSEVVc65J2Zw3+VDOO/EvrozStoUJQ6R43CksorXVhUy76MtrCwoJr1Te747aQizpgxhREZ6vMMTCYUSh8gx2HmgjPmfbOXZ7Dx2HyxneEYa/3zZKVw+YZBupZU2L9SfcDObBvyOyDPHH3f3+2od7w48AwwOYnnA3Z8Ijm0BSoAqoLLm8YVm1gt4DhhK5JnjV7r7vjCvQwS+XGTwyY+28MaaHVS5c8Hovlx71lDOGdlH3VGSNEJLHGaWAjwMXAgUAEvNbLG7r4sqdiuwzt0vNbMMYIOZzXf38uD4+e6+u9ap7wHecff7zOyeYPvusK5DpKyiisUrtzPvoy2s3X6Abp3bc91ZQ5k1ZYjmXkhSCrPFMRHIdfdNAGa2EJgORCcOB7qamQHpwF6gspHzTgfOCz7PA/4XJQ4Jwbb9h3nmk60szM5j36EKTuyXzi9nnMqMcQNJ7ajuKEleYf70DwTyo7YLgEm1yjwELAa2A12Bq9y9OjjmwFtm5sCj7j4n2N/P3QsB3L3QzPqGdQGSfNydTzbtZd5HW3hr3Q4ALhzTj2vPGsqU4b2J/I0jktzCTBx1/QvzWtsXASuAC4ARwNtm9r67HwDOdvftQWJ428w+c/e/xPzlZrOB2QCDBw8+lvgliRwqr+RPn27nqY+38NmOEnqkdmD2uSP43uTBDOqpVWlFooWZOAqAzKjtQURaFtGuB+5zdwdyzWwzcBKQ7e7bAdx9l5m9TKTr6y/ATjPrH7Q2+gO76vryoIUyByArK6t2whIBIuMXv383lyc/2sKBskrG9O/Gry4/ncvGDqBzh5R4hyfSKoWZOJYCo8xsGLANmAlcU6tMHjAVeN/M+gGjgU1mlga0c/eS4PM3gH8J6iwGrgXuC95fCfEapA37NG8f/+eFlWwsKuWS007g+rOHkTWkp7qjRBoRWuJw90ozuw14k8jtuHPdfa2Z3RIcfwT4BfCkma0m0rV1t7vvNrPhwMvBP+D2wLPu/kZw6vuA583sBiKJ54qwrkHaprKKKn7z9uc89v4mTujWmad+MJFzT8yId1giCcMivURtW1ZWlufk5MQ7DGkFlm3dx52LVrKpqJRrJg3mZxefRNfOWj9KpC5mtqxmDl003VMoSaGsoooH39rA4x9sZkD3LjxzwyTOGdUn3mGJJCQlDmnzcrbs5a5Fq9i0u5TvTR7MPRefrGVBRI6D/vVIm3W4vIoH3trA3A83M7BHF569cRJnjVQrQ+R4KXFIm5S9eS93LVrJlj2H+P6UIdw97STS1MoQaRb6lyRtyqHySu5/cwNPfrSFQT27sOCmyUwZ0TveYYm0KUoc0mYs2bSHu15cxdY9h7jurKHcedFotTJEQqB/VZLwDpVX8qs3Iq2Mwb1SWTh7MpOHq5UhEhYlDkloH2/cw90vriJ/3yGuPzvSytDKtSLh0r8wSUilRyr5jzc+46mPtzK0dyrPzZ7CxGG94h2WSFJQ4pCE81Hubu56cRXb9h/mB2cP486LRtOloxYkFGkpShySMA4eqeS+/1rPM5/kMaxPGi/cPIWsoWpliLS0RhOHmfVy970tEYxIfT7M3c1di1axvfgwN54zjJ9+Q60MkXiJpcWxxMxWAE8A/+XJsCqitBolZRX8+399xrNL8hjeJ41Ft0xhwhC1MkTiKZbEcSLwdeAHwH+a2XPAk+7+eaiRSdJ7/4si7nlxNYXFh5l97nD+/sIT9XAlkVag0cQRtDDeJvL41vOBZ4C/M7OVwD3u/nHIMUqSKSmr4N9eX8+C7HxGZKSx6IdnMX5wz3iHJSKBWMY4egPfA2YBO4EfEXkK31jgBWBYiPFJknnv8yJ+9uIqdhwo4+avDecnX1crQ6S1iaWr6mPgaeBb7l4QtT/HzB4JJyxJNofLq7h38Vqey8lnZN90XvzhWYxTK0OkVYolcYyub0Dc3f+jmeORJHTwSCU/eGIpOVv38sPzRnD71FFqZYi0Yu1iKPOWmfWo2TCznmb2ZnghSTIpPlzBrD8uYVnePn43cxx3TztJSUOklYslcWS4+/6aDXffB/SN5eRmNs3MNphZrpndU8fx7mb2qpmtNLO1ZnZ9sD/TzN41s/XB/tuj6txrZtvMbEXwuiSWWKT12Vdazncf/4Q124r5/XfHc+kZA+IdkojEIJauqiozG+zueQBmNgRodC6HmaUADwMXAgXAUjNb7O7roordCqxz90vNLAPYYGbzgUrgp+6+3My6AsvM7O2our9x9wdivkppdYpKjvC9x5ewZU8pc76fxfmjY/pbRERagVgSx/8FPjCz94Ltc4HZMdSbCOS6+yYAM1sITAeiE4cDXc3MgHRgL1Dp7oVAIYC7l5jZemBgrbqSoHYUl3HN459QuL+MJ647U49zFUkwjXZVufsbwHjgOeB5YIK7xzLGMRDIj9ouCPZFewg4GdgOrAZud/fq6AJmNhQYByyJ2n2bma0ys7lmVuetN2Y228xyzCynqKgohnClJRTsO8SVj37MrgNHeOqGiUoaIgkoljEOgCpgF1AMjDGzc2OoY3Xsq93FdRGwAhhAZF7IQ2bW7egJzNKBF4E73P1AsPsPwIigfCHwYF1f7u5z3D3L3bMyMjJiCFfCtmV3KVc+8jH7D5XzzI2TOFMLFIokpFgmAN4I3A4MIvJLfjKRuR0XNFK1AMiM2h5EpGUR7XrgvuB231wz2wycBGSbWQciSWO+u79UU8Hdd0bF9hjw58auQeIvd1cJ1zy2hIqqap69aTKnDuwe75BE5BjF0uK4HTgT2Oru5xPpNoql72cpMMrMhplZR2AmkRnn0fKAqQBm1g8YDWwKxjz+CKx3919HVzCz/lGbM4A1McQicbS+8ABXPfoJ1Q7P3TxFSUMkwcUyOF7m7mVmhpl1cvfPzGx0Y5XcvdLMbgPeBFKAue6+1sxuCY4/AvwCeNLMVhPp2rrb3Xeb2TlEljhZHazMC/Bzd38d+JWZjSXS7bUFuLkpFywta1XBfr4/N5suHVKYf+MkhmekxzskETlOsSSOgmAC4J+ILHS4j692OdUp+EX/eq19j0R93g58o456H1D3GAnuPiuW75b4W7Z1L9fNXUr31A4suGkymb1S4x2SiDSDWFbHnRF8vNfM3gW6A2+EGpUkvI837uGGeUvp160z82+cxIAeXeIdkog0kwYTh5m1A1a5+6kA7v5eQ+VFAP7yeRE3PZXD4F6pzL9xEn27dY53SCLSjBocHA/mVKw0s8EtFI8kuP9et5Mb5+UwPCOdhbMnK2mItEGxjHH0B9aaWTZQWrPT3S8LLSpJSK+vLuTHCz7llAHdmPeDifRI7RjvkEQkBLEkjn8OPQpJeC9/WsBPn1/JuME9eeL6M+nWuUO8QxKRkMQyOK5xDWnQwuw8fvbyaiYP683j12aR1imWv0dEJFHFMnO8hC+XCukIdABK3b1b/bUkWTz18Rb+8ZW1fO3EDB6dNUHP0hBJArG0OLpGb5vZt4isfCtJbs5fNvJvr3/GhWP68dA14+jUXklDJBnEusjhUe7+Jxpfp0rauP985wv+7fXP+NvT+/P7745X0hBJIrF0VX07arMdkEUMD3KStsndeeCtDTz87ka+PW4gv/rO6bRPafLfHyKSwGIZxbw06nMlkfWhpocSjbRq7s4v/ryeuR9u5uqJmfzyW6fRrl2dK8OISBsWyxjH9S0RiLRu1dXO/3tlDfOX5HHdWUP5p0vHEFnEWESSTaN9DGY2L1jksGa7p5nNDTUqaVWqqp27XlzF/CV53Py14UoaIkkulq6q0919f82Gu+8zs3HhhSStSUVVNT99fiWLV27njq+P4vapo5Q0RJJcLImjnZn1dPd9AGbWK8Z6kuDKK6v50YLlvLl2J3dPO4kfnjci3iGJSCsQSwJ4EPjIzBYRuZvqSuCXoUYlcVdWUcUPn1nGuxuK+MdvjuEH5wyLd0gi0krEMjj+lJnlEJm7YcC33X1d6JFJ3Bwqr+Smp3L4MHcPv5xxKt+dNCTeIYlIKxLLPI7JwFp3fyjY7mpmk9x9SejRSYsrKavghidzyNm6lweuOIPvTBgU75BEpJWJZebWH4CDUdulwb5Gmdk0M9tgZrlmdk8dx7ub2atmttLM1prZ9Y3VNbNeZva2mX0RvPeMJRZpXPGhCmb9MZtlefv43cxxShoiUqdYEoe5+9GZ4sHDnWJpqaQADwMXA2OAq81sTK1itwLr3P0M4DzgQTPr2Ejde4B33H0U8E6wLcdpz8EjXP3YJ6zdXszvvzueS88YEO+QRKSViiVxbDKzH5tZh+B1O7AphnoTgVx33+Tu5cBCvjrj3IGuFrm/Mx3YS2R2ekN1pwPzgs/zgG/FEIs0YNeBMmbO+YSNRQd57PtZXHTKCfEOSURasVgSxy3AWcA2oACYBNwUQ72BQH7UdkGwL9pDwMnAdmA1cHvQommobj93LwQI3vvGEIvUY/v+w1w15xO27T/ME9efyXmj9Z9TRBoWy11Vu4CZNdtm1gX4JvBCI1XrmiVWe3HEi4AVRO7YGgG8bWbvx1i34S83mw3MBhg8WI9Mr0venkNc/dgnHDhcwdM3TGTCkF7xDklEEkBMy5qaWYqZXWxmTwGbgatiqFYAZEZtDyLSsoh2PfCSR+QG5z6pkbo7zax/EFd/YFddX+7uc9w9y92zMjIyYgg3ueTuOsgVj35EaXklz940WUlDRGLWYOIws3PN7BEiK+LeCHwDGO7u34nh3EuBUWY2zMw6Emm1LK5VJg+YGnxXP2A0kfGThuouBq4NPl8LvBJDLBLlsx0HmDnnY6qqnQU3Tea0Qd3jHZKIJJB6u6rMrIDIL/Y/AHe6e4mZbXb3Q7Gc2N0rzew24E0gBZjr7mvN7Jbg+CPAL4AnzWw1ke6pu919d/D9X6kbnPo+4HkzuyGI74omX3USW11QzKy5S+jUvh3zb5zMyL7p8Q5JRBKMRd1p+9cHzH5H5I6l1cCzRP6yX+3uw1ssumaSlZXlOTk58Q4j7pZt3ct1c5fSrUsHnr1pEkN6p8U7JBFpxcxsmbtn1d5fb1eVu98ODAV+DZwPfA5kmNmVZqY/UxPMxxv3MOuP2fRO78gLt0xR0hCRY9bgGEcwaP0/7n4TkSRyDZFWyJbQI5Nm878bdnHdE9kM7NGF52+ewoAeXeIdkogksJiXR3f3CuBV4NXgllxJAG+u3cFtzy5nVN+uPH3DRHqnd4p3SCKS4I7puRrufri5A5Hm9+rK7dzx3ApOHdidp66fSPfUDvEOSUTagJjmcUjieSEnn9sXfsqEwT155gYlDRFpPnqSXxv09Cdb+X9/WsPfjOrDnFlZdOmYEu+QRKQNiWWV21f56nIfxUAO8Ki7l4URmBybx9/fxL++tp6pJ/Xl4e+Op3MHJQ0RaV4xrY5L5HkcjwWvA8BO4MRgW1qJh/7nC/71tfVcctoJ/OF7E5Q0RCQUsXRVjXP3c6O2XzWzv7j7uWa2tt5a0mLcnQfe2sDD725kxriB3P+d02mfouErEQlHLL9dMszs6PKywec+wWZ5KFFJzNydX/x5PQ+/u5GrJ2by4BVnKGmISKhiaXH8FPjAzDYSWU9qGPB3ZpbGlw9Ukjiornb+4ZU1PLskj+vOGso/XTqGyDOxRETCE8vzOF43s1FEljs34LOoAfHfhhibNKCyqpq7XlzFS8u38cPzRnDXRaOVNESkRcR6O+4EIkuOtAdONzPc/anQopIGVVRVc8dzK3htVSF/f+GJ/OiCkUoaItJiYrkd92kiT+dbAVQFux1Q4oiDI5VV3Dr/U/57/U5+fslJzD53RLxDEpEkE0uLIwsY4/Wtvy4t5nB5FbOfzuH9L3bzL9NP4ftThsY7JBFJQrEkjjXACUBhyLFIAw4eqeSGJ5eSvWUvv7r8dK48M7PxSiIiIYglcfQB1plZNnCkZqe7XxZaVPJXig9XcN0T2awqKOa3V41l+tiB8Q5JRJJYLInj3rCDkPrtLS1n1h+X8PnOEh6+ZjzTTj0h3iGJSJKL5Xbc91oiEPmqXSVlzHo8my17Spnz/SzOH9033iGJiNQ/c9zMPgjeS8zsQNSrxMwOxHJyM5tmZhvMLNfM7qnj+J1mtiJ4rTGzKjPrZWajo/avCL73jqDOvWa2LerYJcd47a1aYfFhZj76CXl7D/HEdWcqaYhIq1Fvi8Pdzwneux7Lic0sBXgYuBAoAJaa2WJ3Xxf1HfcD9wflLwV+4u57gb3A2KjzbANejjr9b9z9gWOJKxEcKKvgykc/Zl9pBU/fMJGsob3iHZKIyFExTQAMfnn3iy7v7nmNVJsI5Lr7puAcC4HpwLp6yl8NLKhj/1Rgo7tvjSXWtuBPn24jf+9hFtw0WUlDRFqdRlfDM7MfEVlG/W3gteD15xjOPRDIj9ouCPbV9R2pwDTgxToOz+SrCeU2M1tlZnPNrGc955xtZjlmllNUVBRDuK2Du7MgO59TBnRjyoje8Q5HROQrYllG9XZgtLuf4u6nBa/TY6hX1xoY9U0ivBT4MOim+vIEZh2By4AXonb/gchM9rFE5pY8WNcJ3X2Ou2e5e1ZGRkYM4bYOqwqKWV94gJkTBzdeWEQkDmJJHPlEnvjXVAVA9Cy1QcD2esrW1aoAuBhY7u47a3a4+053r3L3aiIPkpp4DLG1WguX5tGlQwrTxw6IdygiInWKZYxjE/C/ZvYafz0B8NeN1FsKjDKzYUQGt2cC19QuZGbdga8B36vjHF8Z9zCz/u5eM4t9BpGZ7W3CwSOVvLJiO988vT/dOneIdzgiInWKJXHkBa+OwSsm7l5pZrcBbwIpwFx3X2tmtwTHHwmKzgDecvfS6PrBuMeFwM21Tv0rMxtLpNtrSx3HE9arK7dzqLxK3VQi0qpZMqxdmJWV5Tk5OfEOo1HTH/qAwxVVvHnHuVomXUTizsyWuXtW7f31tjjM7LfufoeZvUodg9paq6p5rd1ezMqCYj3FT0RavYa6qp4O3tvsRLvWZGF2Ph3bt2PGOC1gKCKtW0Mzx5cF71qrKmSHy6v404ptXHLqCfRIjXkYSUQkLmJ5AuAo4N+BMUDnmv3uPjzEuJLKa6sLKSmr1KC4iCSEWOZxPEFk0l0lcD6RR8Y+3WANaZIF2XkM75PGpGFaXkREWr9YEkcXd3+HyB1YW939XuCCcMNKHp/vLGHZ1n3MnJipQXERSQixzOMoM7N2wBfBvIxtgNb4biYLs/PpkGJcPn5QvEMREYlJLC2OO4BU4MfABCIzvK8NMaakUVZRxUufFvCNMSfQO71TvMMREYlJgy2OYDn1K939TuAgcH2LRJUk3ly7g/2HKrhag+IikkAaegJge3evAiaYOt9DsSA7j8xeXThLy6eLSAJpqMWRDYwHPgVeMbMXgKPrSbn7SyHH1qZt3l3KJ5v2cudFo2nXTnlZRBJHLIPjvYA9RO6kciLP2XBAieM4LFyaR0o744oJGhQXkcTSUOLoa2Z/T2TZ8pqEUaPtr4wYovLKahblFDD1pL707da58QoiIq1IQ4kjBUinaU/ykxj89/qd7Ckt16C4iCSkhhJHobv/S4tFkkQWZOcxoHtnzj0xcR5pKyJSo6F5HBqxDUH+3kN8kLubK7IySdGguIgkoIYSx9QWiyKJPLc0HwOuPDOz0bIiIq1RvYnD3fe2ZCDJoLKqmheW5fO1EzMY2KNLvMMRETkmsSw5Is3k3Q1F7DxwRMuni0hCCzVxmNk0M9tgZrlmdk8dx+80sxXBa42ZVZlZr+DYFjNbHRzLiarTy8zeNrMvgveeYV5Dc1qYnUdG105ccJLWiBSRxBVa4gjWuXoYuJjIQ6CuNrMx0WXc/X53H+vuY4GfAe/V6iI7Pzge/bD0e4B33H0U8E6w3eoVFh/m3Q27uDJrEB1S1NATkcQV5m+wiUCuu29y93JgITC9gfJXAwtiOO90YF7weR7wreMJsqU8v7SAaoerstRNJSKJLczEMRDIj9ouCPZ9hZmlAtOAF6N2O/CWmS0zs9lR+/u5eyFA8F5nv4+ZzTazHDPLKSoqOo7LOH5V1c7zOfmcM7IPg3unxjUWEZHjFWbiaMqM80uBD2t1U53t7uOJdHXdambnNuXL3X2Ou2e5e1ZGRnwn2r3/RRHb9h/WTHERaRPCTBwFQPRkhUHA9nrKzqRWN5W7bw/edwEvE+n6AthpZv0BgvddzRhzKBZk59E7rSMXjukX71BERI5bmIljKTDKzIaZWUciyWFx7UJm1h34GvBK1L40M+ta8xn4BpHFFgnOUfMEwmuj67VGu0rKeGf9Li6fMIiO7TUoLiKJL5Zl1Y+Ju1cGzyh/k8iCiXPdfa2Z3RIcfyQoOgN4y91Lo6r3A14Onh/VHnjW3d8Ijt0HPG9mNwB5wBVhXUNzWLSsgMpq5yrNFBeRNsLc2/5Ct1lZWZ6Tk9N4wWZWXe2c/+D/ckK3zjx385QW/34RkeNhZstqTYcANHM8VB9v2sPWPYc0KC4ibYoSR4gWZOfRvUsHpp16QrxDERFpNkocIdlbWs5ba3cyY9xAOndIiXc4IiLNRokjJC8tL6C8qlrdVCLS5ihxhMDdeTY7j/GDezD6hK7xDkdEpFkpcYRg6ZZ9bCoq1fLpItImKXGEYGF2Hl07teebp/ePdygiIs1OiaOZFR+q4LXVhUwfN4DUjqHNrxQRiRsljmb28qcFHKmsZuaZ6qYSkbZJiaMZuTsLl+Zz2sDunDqwe7zDEREJhRJHM1qRv5/PdpQwc6LWpRKRtkuJoxktzM4ntWMKl50xIN6hiIiERomjmZSUVbB45XYuPX0AXTt3iHc4IiKhUeJoJotXbudwRZW6qUSkzVPiaCYLs/M56YSujM3sEe9QRERCpcTRDNZsK2b1tmKunjiY4OFTIiJtlhJHM1iQnUen9u341tiB8Q5FRCR0ShzH6VB5Ja+s2M7fntaf7qkaFBeRti/UxGFm08xsg5nlmtk9dRy/08xWBK81ZlZlZr3MLNPM3jWz9Wa21sxuj6pzr5lti6p3SZjX0Jg/ryrk4JFKLWgoIkkjtMWUzCwFeBi4ECgAlprZYndfV1PG3e8H7g/KXwr8xN33mlkn4KfuvtzMugLLzOztqLq/cfcHwoq9KRZm5zEiI40zh/aMdygiIi0izBbHRCDX3Te5ezmwEJjeQPmrgQUA7l7o7suDzyXAeqDVDSBs2FHC8rz9GhQXkaQSZuIYCORHbRdQzy9/M0sFpgEv1nFsKDAOWBK1+zYzW2Vmc82szj/1zWy2meWYWU5RUdExXkLDFmTn0TGlHd8ePyiU84uItEZhJo66/gT3espeCnzo7nv/6gRm6USSyR3ufiDY/QdgBDAWKAQerOuE7j7H3bPcPSsjI+MYwm9YWUUVL3+6jW+c0o9eaR2b/fwiIq1VmImjAIieRj0I2F5P2ZkE3VQ1zKwDkaQx391fqtnv7jvdvcrdq4HHiHSJtbg31uyg+HAF12hQXESSTJiJYykwysyGmVlHIslhce1CZtYd+BrwStQ+A/4IrHf3X9cqH/1YvRnAmhBib9Sz2XkM6Z3K5OG94/H1IiJxE9pdVe5eaWa3AW8CKcBcd19rZrcExx8Jis4A3nL30qjqZwOzgNVmtiLY93N3fx34lZmNJdLttQW4OaxrqM/GooNkb97LXdNG066dBsVFJLmE+mzT4Bf967X2PVJr+0ngyVr7PqDuMRLcfVazBnkMnluaT/t2xncmaFBcRJKPZo430ZHKKhYtK+DrJ/ejb9fO8Q5HRKTFKXE00dvrdrK3tFzLp4tI0lLiaKKF2fkM7NGFvxnV/Lf4iogkAiWOJsjbc4gPcndzZVYmKRoUF5EkpcTRBM/l5NHO4MozNSguIslLiSNGFVXVPJ9TwPmj+9K/e5d4hyMiEjdKHDH6n892UVRyRMuni0jSU+KI0cLsPPp168T5ozUoLiLJTYkjBtv2H+a9z4u4MiuT9in6TyYiyU2/BWPw/NJ8HLgyS3M3RESUOBpRVe28kJPPOSP7kNkrNd7hiIjEnRJHI/7yeRHbi8u0fLqISECJoxELsvPok96RqSf3i3coIiKtghJHA3YdKOOdz3Zx+YRBdGyv/1QiIqDE0aAXlhVQVe3MPFPdVCIiNZQ4GpDRtRNXZg1iWJ+0eIciItJqhPogp0R3ZVambsEVEalFLQ4REWkSJQ4REWmSUBOHmU0zsw1mlmtm99Rx/E4zWxG81phZlZn1aqiumfUys7fN7IvgvWeY1yAiIn8ttMRhZinAw8DFwBjgajMbE13G3e9397HuPhb4GfCeu+9tpO49wDvuPgp4J9gWEZEWEmaLYyKQ6+6b3L0cWAhMb6D81cCCGOpOB+YFn+cB32ruwEVEpH5hJo6BQH7UdkGw7yvMLBWYBrwYQ91+7l4IELz3reecs80sx8xyioqKjvkiRETkr4WZOOp6KLfXU/ZS4EN333sMdevk7nPcPcvdszIy9AwNEZHmEmbiKACiJ0EMArbXU3YmX3ZTNVZ3p5n1BwjedzVLtCIiEhNzb9If8rGf2Kw98DkwFdgGLAWucfe1tcp1BzYDme5e2lhdM7sf2OPu9wV3W/Vy97saiaUI2HqMl9IH2H2MdROVrjk56JqTw/Fc8xB3/0qXTWgzx9290sxuA94EUoC5wS/+W4LjjwRFZwBv1SSNhuoGh+8DnjezG4A84IoYYjnmviozy3H3rGOtn4h0zclB15wcwrjm0FocbYV+0JKDrjk56Jqbh2aOi4hIkyhxNG5OvAOIA11zctA1J4dmv2Z1VYmISJOoxSEiIk2ixCEiIk2ixNGAxlb3bWvMLNPM3jWz9Wa21sxuj3dMLcHMUszsUzP7c7xjaQlm1sPMFpnZZ8H/6ynxjilsZvaT4Gd6jZktMLPO8Y6puZnZXDPbZWZrovaFspq4Ekc9Ylndtw2qBH7q7icDk4Fbk+CaAW4H1sc7iBb0O+ANdz8JOIM2fu1mNhD4MZDl7qcSmRs2M75RheJJImv+RQtlNXEljvo1dXXfhOfuhe6+PPhcQuQXSp0LU7YVZjYI+Fvg8XjH0hLMrBtwLvBHAHcvd/f9cQ2qZbQHugSrUqRS//JHCcvd/wLsrbU7lNXElTjqF/Pqvm2RmQ0FxgFL4hxK2H4L3AVUxzmOljIcKAKeCLrnHjeztHgHFSZ33wY8QGSliUKg2N3fim9ULSam1cSbSomjfse9Qm+iMrN0Ikvc3+HuB+IdT1jM7JvALndfFu9YWlB7YDzwB3cfB5TSxh+GFvTrTweGAQOANDP7XnyjSmxKHPVryuq+bYaZdSCSNOa7+0vxjidkZwOXmdkWIl2RF5jZM/ENKXQFQIG717QkFxFJJG3Z14HN7l7k7hXAS8BZcY6ppYSymrgSR/2WAqPMbJiZdSQymLY4zjGFysyMSN/3enf/dbzjCZu7/8zdB7n7UCL/f//H3dv0X6LuvgPIN7PRwa6pwLo4htQS8oDJZpYa/IxPpY3fEBBlMXBt8Pla4JXmOGloq+MmukZW6G2rzgZmAavNbEWw7+fu/nr8QpIQ/AiYH/xBtAm4Ps7xhMrdl5jZImA5kTsHP6UNLj1iZguA84A+ZlYA/BPHsJp4TN+lJUdERKQp1FUlIiJNosQhIiJNosQhIiJNosQhIiJNosQhIiJNosQh0gqZ2XnJslqvJB4lDhERaRIlDpHjYGbfM7NsM1thZo8Gz/Y4aGYPmtlyM3vHzDKCsmPN7BMzW2VmL9c8G8HMRprZf5vZyqDOiOD06VHPzZgfzHrGzO4zs3XBeR6I06VLElPiEDlGZnYycBVwtruPBaqA7wJpwHJ3Hw+8R2QGL8BTwN3ufjqwOmr/fOBhdz+DyBpKhcH+ccAdRJ4HMxw428x6ATOAU4Lz/GuY1yhSFyUOkWM3FZgALA2WaJlK5Bd8NfBcUOYZ4Bwz6w70cPf3gv3zgHPNrCsw0N1fBnD3Mnc/FJTJdvcCd68GVgBDgQNAGfC4mX0bqCkr0mKUOESOnQHz3H1s8Brt7vfWUa6hdX3qWr6/xpGoz1VAe3evJPKQsReJPJTnjaaFLHL8lDhEjt07wHfMrC8cfb7zECL/rr4TlLkG+MDdi4F9ZvY3wf5ZwHvB804KzOxbwTk6mVlqfV8YPCule7Dw5B3A2Ga/KpFGaHVckWPk7uvM7B+At8ysHVAB3Erk4UinmNkyoJjIOAhElrV+JEgM0avSzgIeNbN/Cc7R0AqmXYFXzKwzkdbKT5r5skQapdVxRZqZmR109/R4xyESFnVViYhIk6jFISIiTaIWh4iINIkSh4iINIkSh4iINIkSh4iINIkSh4iINMn/B7psuws3vVnpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization oof the accuracy curve over the epochs\n",
    "plt.plot(model_1_hist.history[\"accuracy\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Training Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758a88f",
   "metadata": {},
   "source": [
    "Across epochs, we can see an increase in training accuracy, with the highest achieved being 88.25%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1967317",
   "metadata": {},
   "source": [
    "### Evaluating the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9a11deaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.2417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24258197844028473, 0.8917332887649536]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_Xle, test_yle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af450df0",
   "metadata": {},
   "source": [
    "When evaluating the model, a high testing accuracy of 89.17% was achieved using the simple model and a reasonably low loss value of 0.24 was attained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed370e6",
   "metadata": {},
   "source": [
    "## New Model Attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ee56b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.6647\n",
      "Epoch 2/11\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4614\n",
      "Epoch 3/11\n",
      "\u001b[1m513/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m model_1\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False), # soft layer already added\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     23\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fitting the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m model_1_hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_Xle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_yle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ### OLIVIA LEFT OFF HERE ###\n",
    "# ###Want to add a soft max layer###\n",
    "\n",
    "# # setting a seed for reproducability \n",
    "# tf.random.set_seed(555)\n",
    "\n",
    "# # Creating the model\n",
    "# model_1 = tf.keras.Sequential([\n",
    "#     # defining hidden layer\n",
    "#     layers.Dense(10, activation = 'relu', kernel_initializer = \"he_normal\", input_shape = (train_Xle.shape[1],)), \n",
    "    \n",
    "#     # dropout layer \n",
    "#     layers.Dropout(0.2),\n",
    "    \n",
    "#     # output layer; binary so 2 neurons since 'softmax' used\n",
    "# #     layers.Dense(2, activation = 'softmax')\n",
    "#     layers.Dense(1)\n",
    "# ])\n",
    "\n",
    "# model_1.compile(\n",
    "# #     loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False), # soft layer already added\n",
    "#     loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#     optimizer = 'adam',\n",
    "#     metrics = ['accuracy'] \n",
    "# )\n",
    "\n",
    "# # Fitting the model\n",
    "# model_1_hist = model_1.fit(train_Xle, train_yle, epochs = 11, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61734b5f",
   "metadata": {},
   "source": [
    "### Plotting Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization oof the accuracy curve over the epochs\n",
    "plt.plot(model_2_hist.history[\"accuracy\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Training Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9b817-6e3a-4bdd-98ec-0bcef814574c",
   "metadata": {},
   "source": [
    "## Prepare data for Other Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fc711-f35b-4f99-8ba2-de92b0e1991a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943588d-8a1e-494a-9bf6-e285ed1e9a22",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ca77e-924b-43f9-835f-b70265394602",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556be068-ef28-45d7-b413-9fc0e7f5ed13",
   "metadata": {},
   "source": [
    "## Classification Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3463516-d5f0-4d61-a63b-b6de404f7428",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9882d-c352-483c-94e7-0601fb38f1a9",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7810963-39f9-492d-867c-6d1642892e84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1e029-292f-4b09-ba92-81196cd25039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
