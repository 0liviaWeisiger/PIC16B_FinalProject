{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdd3c7b",
   "metadata": {},
   "source": [
    "# Predicting United States Real Estate Prices\n",
    "By: Grace Li, Olivia Weisiger and Fionnuala Eastwood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab3975",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Dataset Merging and Preprocessing\n",
    "2. Data Visualization\n",
    "3. Classic Machine Learning Models\n",
    "4. Deep Learning Models\n",
    "5. Analysis of accuracy and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bef22",
   "metadata": {},
   "source": [
    "### Context\n",
    "The United States housing market is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f63040",
   "metadata": {},
   "source": [
    "### Our Goal\n",
    "\n",
    "This project will explore the current United States real-estate market, investigate what factors influence the price of property, and create multiple machine learning models that predict these housing costs throughout the country. More specifically, this will be accomplished through implementation of (add briefly about what models we end up using....) Being able to infer and understand the trends of real estate is extremely valuable economic knowledge that will provide important insights about our country. \n",
    "\n",
    "Furthermore, our project aims to deepen our understanding of societal biases on external structures such as the economy. By merging datasets, we will investigate which underlying factors such as (add briefly when choose other data) affect the prices of houses in order to draw deeper conclusions about intangible factors impacting our economic climate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2a9f0",
   "metadata": {},
   "source": [
    "### Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2b9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c588b0c",
   "metadata": {},
   "source": [
    "This data is from Kaggle's \"USA Real Estate Dataset\" found here: https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd33c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('realtor-data.zip.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d31b33",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "Let's first break down what our dataset looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f643bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2226382, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40f0bd",
   "metadata": {},
   "source": [
    "We have a dataset with over 2 million rows and 12 columns. Since this is way too many samples to process in a reasonable computational time, we will take a random subset of 40,000 of these samples to perform analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef526b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4d145",
   "metadata": {},
   "source": [
    "With our refined sample, let's get an idea of what our dataset looks like by outputting a few rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb9627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597875</th>\n",
       "      <td>10727.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>499900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1429746.0</td>\n",
       "      <td>Kernersville</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>27284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877446</th>\n",
       "      <td>2375.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>164900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>861652.0</td>\n",
       "      <td>Cape Girardeau</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>63701.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496472</th>\n",
       "      <td>102073.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1708296.0</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>New York</td>\n",
       "      <td>14620.0</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>2022-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009399</th>\n",
       "      <td>22930.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1591110.0</td>\n",
       "      <td>Skiatook</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>74070.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461280</th>\n",
       "      <td>51266.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>496990.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>738245.0</td>\n",
       "      <td>Apopka</td>\n",
       "      <td>Florida</td>\n",
       "      <td>32712.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
       "1597875      10727.0      sold  499900.0  4.0   4.0      0.32  1429746.0   \n",
       "1877446       2375.0      sold  164900.0  3.0   2.0      0.33   861652.0   \n",
       "1496472     102073.0      sold  215000.0  NaN   NaN      0.09  1708296.0   \n",
       "1009399      22930.0  for_sale  160000.0  3.0   2.0      0.29  1591110.0   \n",
       "461280       51266.0  for_sale  496990.0  3.0   3.0       NaN   738245.0   \n",
       "\n",
       "                   city           state  zip_code  house_size prev_sold_date  \n",
       "1597875    Kernersville  North Carolina   27284.0         NaN     2021-11-19  \n",
       "1877446  Cape Girardeau        Missouri   63701.0      1424.0     2022-02-28  \n",
       "1496472       Rochester        New York   14620.0      2126.0     2022-01-18  \n",
       "1009399        Skiatook        Oklahoma   74070.0      1464.0            NaN  \n",
       "461280           Apopka         Florida   32712.0      1992.0            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231088b9",
   "metadata": {},
   "source": [
    "Notice that each sample in the dataset is a real estate listing in the United States (the listings are all from 2022-2024), and each sample has 12 features that provide numerical or categorical information about the listing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab60a2",
   "metadata": {},
   "source": [
    "Here is an overview of each feature's meaning and data type:\n",
    "\n",
    "- brokered_by:\n",
    "\n",
    "- status:\n",
    "\n",
    "- price:\n",
    "\n",
    "- bed:\n",
    "\n",
    "- bath:\n",
    "\n",
    "- etc fill in later (look on kaggle these descriptins are provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d56b24",
   "metadata": {},
   "source": [
    "Now that we have an understanding of our data set, we will perform some processing on the data so that it is cleaner to use. Firstly, we will drop some unnecessary columns that do not contribute to our analysis goals. The brokered_by column which encodes the real-estate company in charge of the property is not necessary because we are interested in the qualities of the house itself. Additionally, the status column is not needed because we will use the price set for the house equivalently regardless if it is sold or for sale. Lastly, the previously sold date can be dropped since we are focused on the current selling price. We will trim our dataset from 12 columns to 9 with these modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f7865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['brokered_by', 'status', 'prev_sold_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773a4d7",
   "metadata": {},
   "source": [
    "This dataset contains listings from the United States and all it's territories. For our purposes, we only want to analyze data from the 50 states (and Washington, DC) so let's trim out samples taken from Puerto Rico and the Virgin Islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b008483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['state'] != \"Puerto Rico\") & (df['state'] != \"Virgin Islands\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3dd81",
   "metadata": {},
   "source": [
    "Our next processing step is making sure we don't have any NaN's in our dataset, as empty data values might impact our analysis models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8121f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42516\n"
     ]
    }
   ],
   "source": [
    "#sum up all NaN values present in dataset (in any feature column)\n",
    "print (df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ba406",
   "metadata": {},
   "source": [
    "We see that we have some data entries with no value, so let's remove all rows that contain any NaN values. We will also check the shape of our data frame after this removal to make sure we still have plenty of samples to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23571056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have: 0 NaN entires\n",
      "Our new dataset shape is (30408, 9)\n"
     ]
    }
   ],
   "source": [
    "#remove all rows missing data\n",
    "df = df.dropna()\n",
    "\n",
    "#verify we now have no NaN values, expect a value of zero\n",
    "print (f'We now have: {df.isnull().sum().sum()} NaN entires')\n",
    "\n",
    "#print new shape\n",
    "print (f'Our new dataset shape is {df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d5228",
   "metadata": {},
   "source": [
    "We successfully dropped all empty entries and still have a substantial size data frame to analyze. Now we are ready to merge this dataframe to add more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201cd1d3",
   "metadata": {},
   "source": [
    "### Dataset Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2440ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
